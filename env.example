# ============================================
# Transcription Backend Selection
# ============================================
# Choose which transcription backend to use: 'openai', 'gemini', or 'deepgram'
# Default: openai
TRANSCRIPTION_BACKEND=openai

# ============================================
# OpenAI Configuration
# ============================================
# Required when TRANSCRIPTION_BACKEND=openai
OPENAI_API_KEY=sk-...

# OpenAI model to use for transcription
# Default: gpt-4o-mini-transcribe
# Options: gpt-4o-mini-transcribe, gpt-4o-transcribe
OPENAI_MODEL=gpt-4o-transcribe

# Custom transcription prompt for OpenAI
# Optional - helps guide the transcription model
OPENAI_TRANSCRIPTION_PROMPT="You will hear audio coming from one participant in a conference, your job is to transcribe it. Keep in mind the following: * There might be pauses during which another person speaks, you will not hear anything in this period * The person might speak any language, you need to detect it. However, it is unlikely that the language will switch often"

# Turn detection configuration (JSON)
# Default: {"type":"server_vad","threshold":0.5,"prefix_padding_ms":300,"silence_duration_ms":300}
# OPENAI_TURN_DETECTION={"type":"server_vad","threshold":0.5,"prefix_padding_ms":300,"silence_duration_ms":300}

# ============================================
# Google Gemini Configuration
# ============================================
# Required when TRANSCRIPTION_BACKEND=gemini
# GEMINI_API_KEY=your-gemini-api-key-here

# Gemini model to use for transcription
# Default: gemini-2.0-flash-exp
# Options: gemini-2.0-flash-exp (recommended for transcription), gemini-1.5-pro, gemini-1.5-flash
# Note: Native audio models (gemini-2.5-flash-native-audio-*) are for TTS/voice output, not transcription
# GEMINI_MODEL=gemini-2.0-flash-exp

# Custom transcription prompt for Gemini
# Optional - helps guide the transcription model
# GEMINI_TRANSCRIPTION_PROMPT="Transcribe the following audio. Output only the transcribed text."

# ============================================
# Deepgram Configuration
# ============================================
# Required when TRANSCRIPTION_BACKEND=deepgram
# DEEPGRAM_API_KEY=your-deepgram-api-key-here

# Deepgram model to use for transcription
# Default: nova-2
# Options: nova-2, nova, enhanced, base
# DEEPGRAM_MODEL=nova-2

# Enable automatic punctuation
# Default: false
# DEEPGRAM_PUNCTUATE=true

# Enable speaker diarization (identifies different speakers)
# Default: false
# DEEPGRAM_DIARIZE=false

# ============================================
# Server Configuration
# ============================================
# Port to listen on
# Default: 8080
PORT=8080

# Host to bind to
# Default: 0.0.0.0 (all interfaces)
HOST=0.0.0.0

# ============================================
# Transcription Configuration
# ============================================
# Force commit timeout in seconds (forces transcription when audio stops)
# Set to 0 to disable
# Default: 2
FORCE_COMMIT_TIMEOUT=2

# Broadcast transcripts to other participants as context
# When enabled, transcripts from other participants are added to each participant's
# transcription prompt to provide context
# Default: false
BROADCAST_TRANSCRIPTS=true

# Maximum size of transcript history in bytes
# Default: 5120 (5 KB)
BROADCAST_TRANSCRIPTS_MAX_SIZE=512

# ============================================
# Debugging and Development
# ============================================
# Dump WebSocket messages to files (for debugging/testing)
# Messages are written to DUMP_BASE_PATH/<session-id>/
# Default: false
DUMP_WEBSOCKET_MESSAGES=false

# Dump transcripts to files (for debugging/testing)
# Transcripts are written to DUMP_BASE_PATH/<session-id>/
# Default: false
DUMP_TRANSCRIPTS=false

# Base path for dumps
# Default: /tmp
DUMP_BASE_PATH=/tmp

# Log level: error, warn, info, debug
# Default: info
LOG_LEVEL=info

# Enable debug mode (verbose logging)
# Default: false
DEBUG=false
